# Seq2Seq Transformer Model for Language Translation

This project implements a Sequence-to-Sequence (Seq2Seq) Transformer model for language translation using PyTorch and TorchText. The model is trained on the Multi30k dataset, which contains parallel English-German sentence pairs. Key components include tokenization, vocabulary creation, positional encoding, and the Transformer architecture.
